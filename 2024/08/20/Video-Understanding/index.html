<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/YoungBlogs/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/YoungBlogs/images/Icon.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/YoungBlogs/images/Icon.jpg">
  <link rel="mask-icon" href="/YoungBlogs/images/logo.svg" color="#222">

<link rel="stylesheet" href="/YoungBlogs/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"young-eng.github.io","root":"/YoungBlogs/","images":"/YoungBlogs/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/YoungBlogs/js/config.js"></script>

    <meta name="description" content="视频理解及分析的计算机视觉任务  之前看的时候，不管是论文还是一些博客，感觉都不是很清晰和全面，大家的定义不全面，特别是英文的名称上，这里写一下我的理解： 几个任务：  行为识别(Action Recognition): 实质是对视频的分类任务，可以类别图像领域的分类任务 时序动作定位(Temporal Action Localization): 在时间上对视频进行分类，给出动作的">
<meta property="og:type" content="article">
<meta property="og:title" content="Video Understanding">
<meta property="og:url" content="https://young-eng.github.io/YoungBlogs/2024/08/20/Video-Understanding/index.html">
<meta property="og:site_name" content="Young&#39;s Blog">
<meta property="og:description" content="视频理解及分析的计算机视觉任务  之前看的时候，不管是论文还是一些博客，感觉都不是很清晰和全面，大家的定义不全面，特别是英文的名称上，这里写一下我的理解： 几个任务：  行为识别(Action Recognition): 实质是对视频的分类任务，可以类别图像领域的分类任务 时序动作定位(Temporal Action Localization): 在时间上对视频进行分类，给出动作的">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-08-20T06:12:07.000Z">
<meta property="article:modified_time" content="2024-08-22T02:37:16.209Z">
<meta property="article:author" content="Young">
<meta property="article:tag" content="Video Understanding">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://young-eng.github.io/YoungBlogs/2024/08/20/Video-Understanding/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://young-eng.github.io/YoungBlogs/2024/08/20/Video-Understanding/","path":"2024/08/20/Video-Understanding/","title":"Video Understanding"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Video Understanding | Young's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/YoungBlogs/css/noscript.css">
  </noscript>
<link rel="alternate" href="/YoungBlogs/atom.xml" title="Young's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/YoungBlogs/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Young's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/YoungBlogs/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/YoungBlogs/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/YoungBlogs/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/YoungBlogs/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/YoungBlogs/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3%E5%8F%8A%E5%88%86%E6%9E%90%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%BB%E5%8A%A1"><span class="nav-number">1.</span> <span class="nav-text">视频理解及分析的计算机视觉任务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#deep-learnign-based-action-detection-in-untrimmed-videos-a-survey"><span class="nav-number">2.</span> <span class="nav-text">Deep
Learnign-based Action Detection in Untrimmed Videos: A Survey</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#a-survey-on-deep-learning-based-spatio-temporal-action-detection"><span class="nav-number">3.</span> <span class="nav-text">A
Survey on Deep Learning-based Spatio-temporal Action
Detection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="nav-number">4.</span> <span class="nav-text">参考链接：</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Young"
      src="/YoungBlogs/images/Avatar1.png">
  <p class="site-author-name" itemprop="name">Young</p>
  <div class="site-description" itemprop="description">记录学习和生活</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/YoungBlogs/archives/">
          <span class="site-state-item-count">74</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/YoungBlogs/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/YoungBlogs/tags/">
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Young-eng" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Young-eng" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yuen201718@163.com" title="Email → mailto:yuen201718@163.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>Email</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://young-eng.github.io/YoungBlogs/2024/08/20/Video-Understanding/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/YoungBlogs/images/Avatar1.png">
      <meta itemprop="name" content="Young">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Young's Blog">
      <meta itemprop="description" content="记录学习和生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Video Understanding | Young's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Video Understanding
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-20 14:12:07" itemprop="dateCreated datePublished" datetime="2024-08-20T14:12:07+08:00">2024-08-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-22 10:37:16" itemprop="dateModified" datetime="2024-08-22T10:37:16+08:00">2024-08-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/YoungBlogs/categories/Papers/" itemprop="url" rel="index"><span itemprop="name">Papers</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>9 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4
id="视频理解及分析的计算机视觉任务">视频理解及分析的计算机视觉任务</h4>
<ol type="1">
<li><p>之前看的时候，不管是论文还是一些博客，感觉都不是很清晰和全面，大家的定义不全面，特别是英文的名称上，这里写一下我的理解：</p></li>
<li><p>几个任务：</p>
<ul>
<li><strong>行为识别(Action Recognition)</strong>:
实质是对视频的分类任务，可以类别图像领域的分类任务</li>
<li><strong>时序动作定位(Temporal Action Localization)</strong>:
在时间上对视频进行分类，给出动作的起止时间和类别</li>
<li><strong>时空行为检测(Spatio-Temporal Action Detection)</strong>:
不仅识别出动作出现的<strong>区间</strong>和<strong>类别</strong>，还要在空间范围内用一个bounding
box标记处目标的<strong>位置</strong>。</li>
<li><strong>还有人提出了时空动作定位(Spatio-temporal Action
localization)</strong>：和上一个是一样的</li>
<li>Action Detection在Paperswithcode上的定义： aims to find both where
and when an action occurs within a video clip and classify what the
action is taking place. Typically results are given in the form of
<strong>action tublets</strong>, which are action bounding boxes linked
across time in the video. <em>This is related to temporal localization,
which seeks to identify the start and end frame of an action, and action
recognition, which seeks only to classify which action is taking place
and typically assumes a trimmed video.</em></li>
<li>论文里还提到了<strong>temporal action segmentation</strong>：
针对细粒度的actions和videos with dense occurrence of actions to predict
action label labels at every frame of the video.</li>
</ul></li>
<li><p>时空行为检测的算法：之前的论文都是都是基于行为识别(action
recognition)的，很多都是基于早期的Slowfast的那个检测的方式：需要一个额外的检测器，实现行为检测。也就是在行为识别的基础上，再进行时空行为检测。但这并不是我理想中的方式，所以很多行为识别的算法，在AVA上也能上榜；最近看VideoMAE看了之后，就一直在看这个，没有去看看其它的。</p></li>
<li><p>Action Detection数据集：</p>
<ul>
<li>J-HMDB</li>
<li>UCF101-24</li>
<li>MultiSports</li>
<li>AVA</li>
<li>其中，JHMDB和UCF101-24是密集标注数据集(每一帧都标注，25fps)，这类数据集每个视频只有一个动作，大部分视频是单人做一些语义简单的重复动作；AVA为代表的稀疏标注数据集(隔一段时间标注一帧，1fps)，没有给出明确的动作边界</li>
</ul></li>
</ol>
<span id="more"></span>
<h4
id="deep-learnign-based-action-detection-in-untrimmed-videos-a-survey">Deep
Learnign-based Action Detection in Untrimmed Videos: A Survey</h4>
<blockquote>
<p>作者是来自纽约城市大学的Elahe Vahdani and Yingli
Tian,论文引用[1]:Vahdani, Elahe and Yingli Tian. “Deep Learning-Based
Action Detection in Untrimmed Videos: A Survey.” IEEE Transactions on
Pattern Analysis and Machine Intelligence 45 (2021): 4302-4320.</p>
</blockquote>
<ol type="1">
<li><p>很多action recognition 算法是在untrimmed
video里，真实世界中的视频大部分是漫长的和untrimmed with sparse segments
of interest. temporal activity
detection在没有剪辑的视频里的任务是定位行为的时间边界和分类行为类别。spatio-temporal
action
detection：action在temporal和spatial维度上都进行定位，还需识别行为的类别。因为长的未修剪的视频的标注费时费力，所以
<strong>action detection with limited supervision</strong>
是一个重要的研究方向。</p></li>
<li><p><strong>Temporal Action Detection</strong> 旨在 在untrimmed
video里找到精确的时间边界和行为实例的label。依赖于训练集的标注的availability，可以分为：</p>
<ul>
<li>全监督 action detection: 时间边界和labels of action instances are
available</li>
<li>弱监督action detection：only the video-level labels of action
instances are available, the order of action labels can be provided or
not.</li>
<li>unsupervised action detection: no annotations for action
instances</li>
<li>semi-supervised action detection: 数据被划分为小的子集 <span
class="math inline">\(S_1\)</span> 和大的子集 <span
class="math inline">\(S_2\)</span>，<span
class="math inline">\(S_1\)</span> 中的视频是全标注的，<span
class="math inline">\(S_2\)</span>中的视频没有标注(as in
fully-supervised)或者only annotated with video-level labels(as
weakly-supervised)</li>
<li>self-supervised action detection:
用一个代理任务从数据中抽取信息，然后用于提高性能，例如一般的自监督预训练，然后有监督微调。</li>
<li>Temporal action detection：或者说temporal action localization,
思路和图像中的目标检测类似，会用到 proposals、RoI
pooling这些类似的思路。</li>
</ul></li>
<li><p>Untrimmed
videos通常很长，由于计算资源的限制，很难直接把整个视频给到visual encoder
来提取特征。通常的做法是把视频划分为相同大小的temporal intervals called
<em>snippets</em>，然后对每个snippet都用visual encoder。</p></li>
<li><p><strong>Spatio-temporal Action Detection</strong>:有frame-level
action detection和clip-level action detection</p>
<ul>
<li><strong>frame-level action detection</strong>:
早期的方式是基于滑动窗口的一些扩展方法，要求一些很强的假设：例如cuboid
shape，一个actor的跨帧的固定的空间范围。图像的目标检测启发了识别人类行为
at frame level; 第一阶段，通过region proposal 或者 densely sampled
anchors 产生action proposals，然后第二阶段proposals用于action
classification和localization refinement. 在检测frames里的action
regions之后，一些方法，用光流来获取运动信息，<strong>用linking
algorithm来连接frame-level bounding box into spatio-temporal action
tubes</strong>；有人用dynamic programming approach来连接 resulting
per-frame detection，这个cost
function是基于boxes的检测分数和连续帧之间的重叠；也有人用
tracking-by-detection方法来代替linking
algorithm；另外一组是依赖于actionness measure, 例如pixel-wise
probability of containing any action.
为了估计actionness，它们用low-level cues例如光流；通过thresholding the
actionness scores来抽取action tubes，这个输出是action的rough
localization。这些方法的主要的缺点是没有完全利用视频的时序信息，检测是在每一帧上独立做的，<strong>有效的时序建模是很重要，因为当时序上下文信息是可用的时候，大量的actions才是可识别的。</strong></li>
<li><strong>Clip-level action detection</strong>: 通过在clip
level执行action detection来利用时序信息。Kalogeiton提出了action tubelet
detector(ACT-detector)，输入为一系列的frames，输出action来别和回归的tubelets：系列的带有associated
scores的bounding box。tubelets被连接，来构造action
tubes。Gu等人进一步通过用longer clips和利用I3D pre-trained on the
large-scale video dataset，展示了时序信息的重要性。为了生成action
proposals，把2D region proposals扩展到3D，假定spatial
extent在一个clip内是固定的。随着时间的推移，用较大空间唯一的action
tubes将要违反假设，特别是当clip是很长，涉及actors或者camera的快速移动。</li>
<li><strong>modeling spatio-temporal dependencies</strong>:
理解人类行为要求理解它们身边的人和物体。一些方法用图结构的网络、注意力机制来汇集视频中的物体和人的上下文信息。时空关系通过多层图结构的自注意力来学习，这个能够连接连续clips的entities，因此考虑long-range
spatial and temporal dependencies。</li>
<li>Metrics for Spatio-temporal action detection:
<strong>frame-AP</strong>: measures the area under the precision-recall
curve of the detections for each frame. frame中的IoU大于某个阈值且action
label是正确的，则detection 是正确的。<strong>video-AP</strong>: measures
the area under the precision-recall curve of the action tubes
predictions。如果整个视频帧中，mean per frame IoU大于某个阈值且action
label预测正确，则tube 是正确的.</li>
</ul></li>
</ol>
<h4
id="a-survey-on-deep-learning-based-spatio-temporal-action-detection"><strong>A
Survey on Deep Learning-based Spatio-temporal Action
Detection</strong></h4>
<blockquote>
<p>作者是来自浙大和蚂蚁集团的Peng Wang, Fanwei Zeng和Yuntao
Qian，论文引用[2]:Wang, Peng et al. “A Survey on Deep Learning-based
Spatio-temporal Action Detection.” ArXiv abs/2308.01618 (2023): n.
pag.</p>
</blockquote>
<ol type="1">
<li><p>Spatio-temporal action detection(STAD)
旨在对视频中出现的行为进行分类，然后在空间和时间上进行定位。传统的STAD方式涉及到了滑动窗口，例如deformable
part models, branch and bound approach.
模型主要划分为2类：frame-level和clip-level；<em>frame-level</em>预测 2D
bounding box for a frame; <em>clip-level</em>预测 3D spatio-temporal
tubelets for a clip.</p></li>
<li><p><strong>Frame-level</strong>:
目标检测做的很成功，研究人员将目标检测的模型泛化到STAD
领域，直接的思路是：把STAD in video视为 2D image
检测的集合。具体地说，在每一帧上用action detector来检测得到
<strong>frame-level 2D bounding box</strong>。然后用<strong>linking or
tracking算法</strong>关联这些frame-level detection results，生成
<strong>3D action proposals</strong>。作者从<strong>Temporal
context</strong>、<strong>3D CNN</strong>、<strong>High efficiency and
real-time speed</strong>、<strong>Visual Relation
Modeling</strong>这几个角度给出了相关的算法。有些借鉴了
RCNN、FasterRCNN的思路，用了RPN网络，然后用两个分支分别处理RGB和光流；然后融合外观和运动信息，Linked
up里得到 class-specific action tubes. 也有基于actionness
maps的方法。<strong>actionness是指在图像的特定位置包含一般的action
instance的可能性</strong>。
上述这些STAD方法独立的对待frame，忽视了时序上下文关系。为了克服这个问题，有人提出了<strong>cascade
proposal and location anticipation
model(CPLA)</strong>的方法，能够推理发生在两帧之间的运动趋势。用
<em>frame <span class="math inline">\(I_t\)</span> 上检测到的bbox来推理
<span class="math inline">\(I_{t+k}\)</span> frame上对应的 bbox。<span
class="math inline">\(k\)</span>是 anticipation gap</em>.
除了通过光流来获取视频里的运动特性之外，可以用 <font color=red> 3D CNN
</font>
来从多个相邻帧提取运动信息。后续的还有用<strong>X3D</strong>网络、<strong>ACDnet</strong>、将<strong>光流和RGB</strong>嵌入到一个单流网络中，利用光流来modulate
RGB特征、用<strong>SSD</strong>作为检测器、借鉴YOLO的<strong>YOWO</strong>：3D
CNN来提取时空信息，2D
model来提取空间信息、<strong>WOO</strong>：单个统一的网络，只用一个backbone来做actor
localization和action
classification、<strong>SE-STAD</strong>用FCOS作为目标检测器、<strong>EVAD</strong>用ViTs，通过drop
out non-kkeyframe tokens减小计算开销，refine scenen
context来增强模型性能。</p></li>
</ol>
<h4 id="参考链接">参考链接：</h4>
<ul>
<li>https://0809zheng.github.io/2021/07/15/stad.html：
时空行为检测的比较好的介绍</li>
</ul>
<figure>
<img
src="https://d3i71xaburhd42.cloudfront.net/2217f65a3fade532f079dbefe1230b47063417b7/8-Figure7-1.png"
alt="Spatio-Temporal Action Detection Task" />
<figcaption aria-hidden="true">Spatio-Temporal Action Detection
Task</figcaption>
</figure>
<figure>
<img
src="https://d3i71xaburhd42.cloudfront.net/471baa377495a4175bbb2097809e0c64b8655d93/2-Figure1-1.png"
alt="Spatio-temporal action detection" />
<figcaption aria-hidden="true">Spatio-temporal action
detection</figcaption>
</figure>
<figure>
<img
src="https://d3i71xaburhd42.cloudfront.net/471baa377495a4175bbb2097809e0c64b8655d93/2-Table1-1.png"
alt="Comparision" />
<figcaption aria-hidden="true">Comparision</figcaption>
</figure>
<figure>
<img
src="https://d3i71xaburhd42.cloudfront.net/471baa377495a4175bbb2097809e0c64b8655d93/2-Figure2-1.png"
alt="illustration" />
<figcaption aria-hidden="true">illustration</figcaption>
</figure>
<figure>
<img
src="https://d3i71xaburhd42.cloudfront.net/471baa377495a4175bbb2097809e0c64b8655d93/3-Figure3-1.png"
alt="Taxonomy of STAD models" />
<figcaption aria-hidden="true">Taxonomy of STAD models</figcaption>
</figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/YoungBlogs/tags/Video-Understanding/" rel="tag"># Video Understanding</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/YoungBlogs/2024/08/19/ollama-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/" rel="prev" title="ollama 大模型部署">
                  <i class="fa fa-angle-left"></i> ollama 大模型部署
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2023 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-user"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Young</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">44k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:40</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="100" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/YoungBlogs/js/comments.js"></script><script src="/YoungBlogs/js/utils.js"></script><script src="/YoungBlogs/js/motion.js"></script><script src="/YoungBlogs/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/YoungBlogs/js/third-party/math/mathjax.js"></script>



</body>
</html>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Young&#39;s Blog</title>
  
  
  <link href="https://young-eng.github.io/YoungBlogs/atom.xml" rel="self"/>
  
  <link href="https://young-eng.github.io/YoungBlogs/"/>
  <updated>2024-02-20T14:48:58.751Z</updated>
  <id>https://young-eng.github.io/YoungBlogs/</id>
  
  <author>
    <name>Young</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>å›´åŸ</title>
    <link href="https://young-eng.github.io/YoungBlogs/2024/02/02/%E5%9B%B4%E5%9F%8E/"/>
    <id>https://young-eng.github.io/YoungBlogs/2024/02/02/%E5%9B%B4%E5%9F%8E/</id>
    <published>2024-02-02T15:17:57.000Z</published>
    <updated>2024-02-20T14:48:58.751Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å›´åŸ">ã€Šå›´åŸã€‹</h3><blockquote><p>æ˜¯é’±é’Ÿä¹¦å…ˆç”Ÿçš„ä½œå“ï¼Œâ€œå›´åŸâ€ä¸€è¯ç»å¸¸åœ¨ç”Ÿæ´»ä¸­å¬åˆ°ï¼Œå¾ˆæ—©å°±å¬è¯´äº†è¿™æœ¬ä¹¦ï¼Œè¿‘æ¥ç»ˆäºå¦‚æ„¿ä¹°äº†ä¸€æœ¬ï¼Œæƒ³æ¥é—²æš‡æ—¶åˆ†æ¥è¯»ä¸€è¯»ï¼Œå°‘çœ‹äº›æ‰‹æœºç½‘é¡µèµ„è®¯ï¼Œå¤šå»çœ‹çœ‹æ„Ÿå…´è¶£çš„ä¹¦ç±ï¼Œå…ˆæŒ–ä¸ªå‘ï¼Œä»¥åå†æ…¢æ…¢å¡«ã€‚åç»­ä¼šçœ‹ä¸€äº›ä¹¦ï¼Œä¹Ÿä¼šé™†ç»­æ›´æ–°åˆ°ä¸»é¡µã€‚</p></blockquote><h4 id="ç« èŠ‚æ•…äº‹">ç« èŠ‚æ•…äº‹</h4><p>ç›®å‰è¯»åˆ°äº†æ–¹æ¸é¸¿ç•™æ´‹å›æ¥åï¼Œåœ¨å®¶é‡Œçš„æƒ…èŠ‚ï¼Œåç»­ä¼šç»§ç»­æ›´æ–°ã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;å›´åŸ&quot;&gt;ã€Šå›´åŸã€‹&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;æ˜¯é’±é’Ÿä¹¦å…ˆç”Ÿçš„ä½œå“ï¼Œâ€œå›´åŸâ€ä¸€è¯ç»å¸¸åœ¨ç”Ÿæ´»ä¸­å¬åˆ°ï¼Œå¾ˆæ—©å°±å¬è¯´äº†è¿™æœ¬ä¹¦ï¼Œè¿‘æ¥ç»ˆäºå¦‚æ„¿ä¹°äº†ä¸€æœ¬ï¼Œæƒ³æ¥é—²æš‡æ—¶åˆ†æ¥è¯»ä¸€è¯»ï¼Œå°‘çœ‹äº›æ‰‹æœºç½‘é¡µèµ„è®¯ï¼Œå¤šå»çœ‹çœ‹æ„Ÿå…´è¶£çš„ä¹¦ç±ï¼Œå…ˆæŒ–ä¸ªå‘ï¼Œä»¥åå†æ…¢æ…¢å¡«ã€‚åç»­ä¼šçœ‹ä¸€äº›ä¹¦ï¼Œä¹Ÿä¼š</summary>
      
    
    
    
    <category term="Books" scheme="https://young-eng.github.io/YoungBlogs/categories/Books/"/>
    
    
    <category term="é•¿ç¯‡å°è¯´" scheme="https://young-eng.github.io/YoungBlogs/tags/%E9%95%BF%E7%AF%87%E5%B0%8F%E8%AF%B4/"/>
    
  </entry>
  
  <entry>
    <title>DETR</title>
    <link href="https://young-eng.github.io/YoungBlogs/2024/02/01/DETR/"/>
    <id>https://young-eng.github.io/YoungBlogs/2024/02/01/DETR/</id>
    <published>2024-02-01T15:38:17.000Z</published>
    <updated>2024-02-01T15:38:17.186Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>SSD</title>
    <link href="https://young-eng.github.io/YoungBlogs/2024/02/01/SSD/"/>
    <id>https://young-eng.github.io/YoungBlogs/2024/02/01/SSD/</id>
    <published>2024-02-01T15:37:34.000Z</published>
    <updated>2024-02-01T15:37:34.798Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>MAE</title>
    <link href="https://young-eng.github.io/YoungBlogs/2024/02/01/MAE/"/>
    <id>https://young-eng.github.io/YoungBlogs/2024/02/01/MAE/</id>
    <published>2024-02-01T15:37:24.000Z</published>
    <updated>2024-02-20T11:49:30.178Z</updated>
    
    <content type="html"><![CDATA[<h3 id="masked-autoencoders-are-scalable-vision-learners1"><spanclass="math inline">\(Masked\ Autoencoders\ Are\ Scalable\ Vision\Learners^{[1]}\)</span></h3><blockquote><p>ä½œè€…æ˜¯æ¥è‡ªFAIRçš„æºæ˜ã€Xinlei Chenã€Saining Xieç­‰ã€‚è®ºæ–‡å¼•ç”¨[1]ï¼šHe,Kaiming et al. â€œMasked Autoencoders Are Scalable Vision Learners.â€ 2022IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)(2021): 15979-15988.</p></blockquote><p>ä»¥ä¸‹â€œæˆ‘ä»¬â€æŒ‡ä»£ä½œè€…</p><h4 id="æ‘˜è¦">æ‘˜è¦</h4><ol type="1"><li><p>MAEï¼šæ©ç è‡ªç¼–ç æ˜¯å¯æ‰©å±•çš„è‡ªç›‘ç£å­¦ä¹ å™¨ã€‚æ€è·¯ï¼šå¯¹è¾“å…¥å›¾ç‰‡çš„patchesè¿›è¡Œéšæœºæ©ç ï¼Œç„¶åé‡æ„ç¼ºå¤±çš„åƒç´ ã€‚ä¸¤ä¸ªcoredesignï¼š</p><ul><li>éå¯¹ç§°çš„encoder-decoderæ¶æ„ï¼›encoderåªå¯¹patchesçš„visiblesubsetè¿›è¡Œæ“ä½œã€‚lightweight decoderä»latent representationå’Œmasktokensä¸­é‡å»ºåŸå§‹å›¾ç‰‡ã€‚</li><li>å¯¹è¾“å…¥å›¾ç‰‡è¿›è¡Œé«˜æ¯”ä¾‹æ©ç ï¼Œä¾‹å¦‚75%ï¼Œèƒ½å¤Ÿäº§ç”Ÿé‡è¦å’Œæœ‰æ„ä¹‰çš„è‡ªç›‘ç£ä»»åŠ¡ã€‚</li></ul><p>å°†ä¸¤è€…è¿›è¡Œè€¦åˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆå’Œé«˜æ ¡åœ°è®­ç»ƒå¤§çš„æ¨¡å‹ã€‚å¯æ‰©å±•çš„æ–¹å¼èƒ½å¤Ÿå­¦ä¹ high-capacitymodelsï¼Œæ‰©å±•æ€§å¾ˆå¥½ã€‚æ™®é€šçš„(vanilla)ViT-Hugeæ¨¡å‹åœ¨ImageNet-1Kä¸Šè¾¾åˆ°87.8%çš„bestaccuracyã€‚åœ¨ä¸‹æ¸¸çš„ä»»åŠ¡ä¸Šè¿ç§»çš„èƒ½åŠ›è¶…è¿‡äº†ç›‘ç£çš„é¢„è®­ç»ƒï¼Œå±•ç¤ºå‡ºæ¥promisingscaling behaviorã€‚</p></li></ol><h4 id="æ€»ç»“">æ€»ç»“ï¼š</h4><span id="more"></span><ol type="1"><li><p>æ·±åº¦å­¦ä¹ è§è¯äº†èƒ½åŠ›å’Œå®¹é‡ä¸æ–­å¢é•¿çš„æ¶æ„çš„çˆ†ç‚¸ï¼›åœ¨ç¡¬ä»¶çš„è¿›æ­¥ä¸‹ï¼Œæ¨¡å‹å¾ˆå®¹æ˜“åœ¨1 millionå›¾åƒä¸Šè¿‡æ‹Ÿåˆï¼Œå¼€å§‹éœ€è¦æ•°ä»¥äº¿è®¡çš„--é€šå¸¸æ˜¯å…¬å¼€çš„ä¸å¯è·å–çš„--æ ‡æ³¨æ•°æ®ã€‚å¯¹å¤§é‡æ•°æ®çš„éœ€æ±‚åœ¨NLPä¸­é€šè¿‡è‡ªå·±æ‹¿åº¦é¢„è®­ç»ƒå·²ç»æˆåŠŸè§£å†³ã€‚è§£å†³æ–¹æ³•æ˜¯ï¼šGPTä¸­åŸºäºè‡ªå›å½’çš„æ¨¡å‹å’ŒBERTä¸­çš„MAEã€‚å®ƒä»¬åœ¨æ¦‚å¿µä¸Šéƒ½å¾ˆç®€å•ï¼š<strong><em>"theyremove a portion of the data and learn to predict the removed content.These methods now enable training of generalizable NLP models containingover one hundred billion parameters."</em></strong></p></li><li><p>MAEè¿™ä¸ªideaï¼Œæ˜¯ä¸€èˆ¬çš„denosing autoencodersçš„ä¸€ç§å½¢å¼ï¼Œis naturaland applicable in computer vision aswellã€‚ç›¸å…³çš„ç ”ç©¶æ—©äºBERTã€‚å°½ç®¡åœ¨BERTæˆåŠŸä¹‹åï¼Œå¾ˆå¤šé‡è¦çš„å…´è¶£åœ¨è¿™ä¸ªideaä¸Šï¼Œautoencodingçš„æ–¹æ³•çš„è¿›æ­¥åœ¨visionä¸­ï¼Œè½åäºNLPã€‚<strong><em>whatmakes MAE different between vision and languange?</em></strong>æˆ‘ä»¬å°è¯•ä»ä¸‹é¢çš„è§’åº¦å›ç­”è¿™ä¸ªé—®é¢˜ï¼š</p><ul><li><p>in vision,å·ç§¯ç½‘ç»œåœ¨è¿‡å»åå¹´å ä¸»å¯¼åœ°ä½ï¼Œå·ç§¯æ“ä½œæ˜¯å…¸å‹åœ°åœ¨å›ºå®šçš„gridsä¸Šè¿›è¡Œæ“ä½œï¼Œä¸æ˜¯ç›´æ¥integrateindicators such as mask tokens or positional embeddings intoå·ç§¯ç½‘ç»œã€‚è¿™ä¸ªæ¶æ„çš„å·®è·ï¼Œåœ¨ViTå¼•å…¥ä¹‹åå¾—åˆ°äº†è§£å†³ï¼Œä¸å†æ˜¯ä¸€ä¸ªéšœç¢</p></li><li><p>informationdensityåœ¨è¯­è¨€å’Œè§†è§‰ä¸­æ˜¯ä¸åŒçš„ã€‚è¯­è¨€æ˜¯äººç±»äº§ç”Ÿçš„ä¿¡å·ï¼šé«˜åº¦çš„è¯­ä¹‰å’Œä¿¡æ¯å¯†åº¦ã€‚å½“è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹æ¯ä¸ªå¥å­ä¸­å°‘è®¸çš„ç¼ºå¤±çš„å•è¯æ—¶ï¼Œè¿™ä¸ªä»»åŠ¡ä¼¼ä¹å¼•å‡ºå¤æ‚çš„è¯­è¨€ç†è§£ã€‚å›¾åƒï¼Œç›¸åï¼Œæ˜¯è‡ªç„¶çš„ä¿¡å·ï¼Œæœ‰å¾ˆå¤šç©ºé—´å†—ä½™ï¼Œ<strong><em>amissing patch can be recovered from neighboring patches with littlehigh-level understanding of parts, objects and scenes. To overcome thisdifference and encourage learning usefulfeatures</em></strong>æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„ç­–ç•¥ï¼Œåœ¨è®¡ç®—æœºè§†è§‰é‡Œæ•ˆæœå¾ˆå¥½ï¼š<strong><em>maskinga very high portion of randompathces</em></strong>è¿™ä¸ªç­–ç•¥èƒ½å¤Ÿå‡å°‘å†—ä½™ï¼Œåˆ›å»ºä¸€ä¸ªè‡ªç›‘ç£çš„ä»»åŠ¡ï¼Œè¦æ±‚è¶…è¶Šä½çº§å›¾åƒç»Ÿè®¡çš„å…¨å±€ç†è§£ã€‚</p></li><li><p>Autoencoder's Decoder, <strong><em>which maps the latentrepresentation back to the input, plays a different role betweenreconstructing text andimages</em></strong>åœ¨è§†è§‰é‡Œï¼Œdecoderé‡å»ºåƒç´ ï¼Œå®ƒçš„è¾“å‡ºæ˜¯æ¯”æ™®é€šè¯†åˆ«ä»»åŠ¡æ›´ä½çº§çš„è¯­ä¹‰ã€‚å’Œè¯­è¨€ç›¸æ¯”ï¼Œè¯­è¨€çš„decoderé¢„æµ‹<em>missingwords</em>ï¼ŒåŒ…å«ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚åœ¨BERTä¸­ï¼Œdecoderæ˜¯æ— å…³ç´§è¦çš„(trivial)ï¼›æˆ‘ä»¬å‘ç°ï¼Œå¯¹äºå›¾åƒï¼Œdecoderçš„è®¾è®¡åœ¨å†³å®šå­¦ä¹ åˆ°çš„latentrepresentationçš„è¯­ä¹‰levelæ˜¯è‡³å…³é‡è¦çš„ã€‚</p></li></ul><p>é€šè¿‡ä»¥ä¸Šåˆ†æï¼Œæå‡ºäº†MAE for visual representationlearningã€‚MAEå¯¹è¾“å…¥å›¾åƒçš„patcheséšæœºè¿›è¡Œmaskï¼Œåœ¨åƒç´ ç©ºé—´é‡å»ºç¡®å®çš„patchesã€‚encoder-decoderæ˜¯éå¯¹ç§°çš„è®¾è®¡ã€‚<strong><em>encoderoperates only on the visible subset of patches(without mask tokens),decoder is lightweight and reconstructs the input from the latentrepresentation along with mask tokens</em></strong>ã€‚å°†mask tokens shiftåˆ°éå¯¹ç§°çš„encoder-decoderä¸­çš„å°çš„decoderä¸­èƒ½å¤Ÿå‡å°è®¡ç®—é‡ã€‚</p></li><li><p>Related work:</p><ul><li>Masked language modelingå’Œ its autoregressive counterparts likeBERTã€GPTï¼Œæ˜¯NLPä¸­å¾ˆæˆåŠŸçš„é¢„è®­ç»ƒæ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•ä¿ç•™è¾“å…¥åºåˆ—çš„ä¸€éƒ¨åˆ†ï¼Œè®­ç»ƒæ¨¡å‹æ¥é¢„æµ‹ç¡®å®çš„å†…å®¹ã€‚è¿™äº›æ–¹æ³•å±•ç¤ºå‡ºäº†å¾ˆå¥½çš„æ‰©å±•æ€§ï¼Œå¤§é‡çš„è¯æ®è¡¨æ˜è¿™äº›é¢„è®­ç»ƒçš„è¡¨å¾åœ¨å¾ˆå¤šä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ³›åŒ–æ€§å¾ˆå¥½ã€‚</li><li>Autoencodingæ˜¯ä¸€ä¸ªlearningrepresentationçš„ç»å…¸æ–¹æ³•ã€‚æœ‰ä¸€ä¸ªencoderå°†è¾“å…¥æ˜ å°„åˆ°latentrepresentationï¼Œä¸€ä¸ªdecoderé‡å»ºè¾“å…¥ã€‚ä¾‹å¦‚ï¼šPCAå’Œk-meanséƒ½æ˜¯autoencoderã€‚Denoising Autoencodersæ˜¯ä¸€ç±»ç ´åè¾“å…¥ä¿¡å·ã€å­¦ä¹ é‡å»ºåŸå§‹çš„æ²¡æœ‰ç ´åçš„ä¿¡å·ã€‚ä¸€äº›æ–¹æ³•å¯ä»¥è¢«è§†ä¸ºä¸€ç§generalizedDAE åœ¨ä¸åŒçš„corruptionsæƒ…å†µä¸‹ã€‚åƒæ˜¯masking pixels æˆ–è€…removing colorchannelsã€‚MAEæ˜¯denoisingautoencodingçš„ä¸€ç§ï¼Œä½†æ˜¯å’Œç»å…¸çš„DAEåœ¨å¾ˆå¤šæ–¹é¢ä¸åŒã€‚</li><li>Masked image encodingé€šè¿‡ä»maskedçš„å›¾åƒä¸­å­¦ä¹ representationã€‚Contextencoderç”¨å·ç§¯ç½‘ç»œä¿®å¤å¤§çš„ç¡®å®çš„åŒºåŸŸã€‚å—NLPæˆåŠŸçš„motivatedï¼Œè¿‘æœŸç›¸å…³çš„å·¥ä½œéƒ½æ˜¯åŸºäºTransformersã€‚iGPToperates on sequences of pixels and predicts unknownpixelsã€‚BEiTæå‡ºäº†é¢„æµ‹discrete tokensã€‚</li><li>è‡ªç›‘ç£å­¦ä¹  focusing on different pretext tasks for pre-training.è¿‘æœŸï¼Œå¯¹æ¯”å­¦ä¹ (contrastive learning)å¾ˆæµè¡Œã€‚models image similarity anddissimilarity(or only similarity) between two or more views.å¯¹æ¯”å­¦ä¹ åŠç›¸å…³çš„æ–¹æ³•ä¾èµ–äºæ•°æ®å¢å¼ºã€‚Autoencoding pursues a conceptuallydifferent directionã€‚</li></ul></li><li><p>Approach:</p><ul><li>MAEçš„Decoderä»…åœ¨pre-trainingæœŸé—´ä½¿ç”¨ï¼Œç”¨æ¥è¿›è¡Œå›¾åƒé‡å»ºä»»åŠ¡ã€‚lossfunction è®¡ç®—mean square error betweené‡å»ºçš„å’ŒåŸå§‹çš„å›¾åƒï¼ˆåƒç´ ç©ºé—´ï¼‰ï¼Œä»…è®¡ç®—masked patchesï¼Œsimilar toBERTã€‚</li></ul></li></ol><h4 id="discussion-conclusion">Discussion &amp; Conclusion</h4><ul><li><p>ç®€å•çš„æ‰©å±•æ€§è‰¯å¥½çš„ç®—æ³•æ˜¯æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒã€‚åœ¨NLPä¸­ï¼Œç®€å•çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å¯ä»¥ä»æŒ‡æ•°çº§æ‰©å±•çš„æ¨¡å‹ä¸­è·ç›Šã€‚åœ¨è®¡ç®—æœºè§†è§‰ä¸­ï¼Œå®é™…çš„é¢„è®­ç»ƒçš„èŒƒå¼ä¸»è¦æ˜¯ç›‘ç£å­¦ä¹ ã€‚åœ¨ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åœ¨ImageNetå’Œè¿ç§»å­¦ä¹ ä¸­è§‚å¯Ÿåˆ°ï¼Œä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ï¼Œæ˜¯ä¸€ä¸ªç®€å•çš„ç±»ä¼¼äºNLPä¸­çš„technquesçš„è‡ªç›‘ç£æ–¹æ³•ã€‚åœ¨è§†è§‰ä¸­çš„è‡ªç›‘ç£å­¦ä¹ å¯èƒ½ç°åœ¨æ­£åœ¨å¼€å§‹ç±»ä¼¼NLPä¸­çš„è½¨è¿¹ã€‚</p></li><li><p>å›¾åƒå’Œè¯­è¨€ï¼Œæ˜¯å¦ä¸€ç§ä¸åŒæœ¬è´¨çš„ä¿¡å·ã€‚å›¾è±¡æ˜¯è®°å½•çš„å…‰çº¿ï¼Œæ²¡æœ‰å°†è¯­ä¹‰åˆ†è§£æˆæ–‡å­—çš„è§†è§‰æ¨¡æ‹Ÿã€‚inteadof attempting to remove objects, we remove random patches that mostlikely do not form a semantic segment. Likewiseï¼ŒMAEé‡å»ºåƒç´ ï¼Œè¿™ä¸æ˜¯è¯­ä¹‰å®ä½“(semanticentities)ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œæˆ‘ä»¬çš„MAEæ–¹æ³•èƒ½å¤Ÿæ¨æ–­å‡ºå¤æ‚çš„ã€æ•´ä½“çš„é‡å»ºï¼Œè¡¨æ˜ä»–èŒè´­å­¦ä¹ å¤§é‡çš„è§†è§‰æ¦‚å¿µ(visualconcepts)ã€‚æˆ‘ä»¬è®¾æƒ³ï¼Œthis behavior occurs by way of a rich hiddenrepresentation inside the MAEã€‚</p></li></ul><figure><imgsrc="https://d3i71xaburhd42.cloudfront.net/6351ebb4a3287f5f3e1273464b3b91e5df5a16d7/1-Figure1-1.png"alt="MAE Architecture" /><figcaption aria-hidden="true">MAE Architecture</figcaption></figure><p><strong><em><span class="math inline">\(Figure\ 1^{[1]}\)</span>. OurMAE architecture. During pre-training, a large random subset of imagepatches (e.g., 75%) is masked out. The encoder is applied to the smallsubset of visible patches. Mask tokens are introduced after the encoder,and the full set of encoded patches and mask tokens is processed by asmall decoder that reconstructs the original image in pixels. Afterpre-training, the decoder is discarded and the encoder is applied touncorrupted images (full sets of patches) for recognitiontasks</em></strong></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;masked-autoencoders-are-scalable-vision-learners1&quot;&gt;&lt;span
class=&quot;math inline&quot;&gt;&#92;(Masked&#92; Autoencoders&#92; Are&#92; Scalable&#92; Vision&#92;
Learners^{[1]}&#92;)&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;ä½œè€…æ˜¯æ¥è‡ªFAIRçš„æºæ˜ã€Xinlei Chenã€Saining Xieç­‰ã€‚è®ºæ–‡å¼•ç”¨[1]ï¼šHe,
Kaiming et al. â€œMasked Autoencoders Are Scalable Vision Learners.â€ 2022
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
(2021): 15979-15988.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ä»¥ä¸‹â€œæˆ‘ä»¬â€æŒ‡ä»£ä½œè€…&lt;/p&gt;
&lt;h4 id=&quot;æ‘˜è¦&quot;&gt;æ‘˜è¦&lt;/h4&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;MAEï¼šæ©ç è‡ªç¼–ç æ˜¯å¯æ‰©å±•çš„è‡ªç›‘ç£å­¦ä¹ å™¨ã€‚æ€è·¯ï¼šå¯¹è¾“å…¥å›¾ç‰‡çš„patchesè¿›è¡Œéšæœºæ©ç ï¼Œç„¶åé‡æ„ç¼ºå¤±çš„åƒç´ ã€‚ä¸¤ä¸ªcore
designï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;éå¯¹ç§°çš„encoder-decoderæ¶æ„ï¼›encoderåªå¯¹patchesçš„visible
subsetè¿›è¡Œæ“ä½œã€‚lightweight decoderä»latent representationå’Œmask
tokensä¸­é‡å»ºåŸå§‹å›¾ç‰‡ã€‚&lt;/li&gt;
&lt;li&gt;å¯¹è¾“å…¥å›¾ç‰‡è¿›è¡Œé«˜æ¯”ä¾‹æ©ç ï¼Œä¾‹å¦‚75%ï¼Œèƒ½å¤Ÿäº§ç”Ÿé‡è¦å’Œæœ‰æ„ä¹‰çš„è‡ªç›‘ç£ä»»åŠ¡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å°†ä¸¤è€…è¿›è¡Œè€¦åˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆå’Œé«˜æ ¡åœ°è®­ç»ƒå¤§çš„æ¨¡å‹ã€‚å¯æ‰©å±•çš„æ–¹å¼èƒ½å¤Ÿå­¦ä¹ high-capacity
modelsï¼Œæ‰©å±•æ€§å¾ˆå¥½ã€‚æ™®é€šçš„(vanilla)
ViT-Hugeæ¨¡å‹åœ¨ImageNet-1Kä¸Šè¾¾åˆ°87.8%çš„best
accuracyã€‚åœ¨ä¸‹æ¸¸çš„ä»»åŠ¡ä¸Šè¿ç§»çš„èƒ½åŠ›è¶…è¿‡äº†ç›‘ç£çš„é¢„è®­ç»ƒï¼Œå±•ç¤ºå‡ºæ¥promising
scaling behaviorã€‚&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;æ€»ç»“&quot;&gt;æ€»ç»“ï¼š&lt;/h4&gt;</summary>
    
    
    
    <category term="Papers" scheme="https://young-eng.github.io/YoungBlogs/categories/Papers/"/>
    
    
    <category term="self-supervised" scheme="https://young-eng.github.io/YoungBlogs/tags/self-supervised/"/>
    
  </entry>
  
  <entry>
    <title>VideMAE</title>
    <link href="https://young-eng.github.io/YoungBlogs/2024/01/26/VideMAE/"/>
    <id>https://young-eng.github.io/YoungBlogs/2024/01/26/VideMAE/</id>
    <published>2024-01-26T01:29:03.000Z</published>
    <updated>2024-01-26T15:45:01.504Z</updated>
    
    <content type="html"><![CDATA[<h3id="videomae-v2-scaling-video-masked-autoencoders-with-dual-masking1"><spanclass="math inline">\(VideoMAE\ v2: Scaling\ Video\ Masked\Autoencoders\ with\ Dual\ Masking^{[1]}\)</span> ğŸï¸</h3><blockquote><p>ä½œè€…ä»¬æ˜¯æ¥è‡ªå—å¤§ Novel Software Technology Labã€ä¸Šæµ·AILabå’Œæ·±åœ³å…ˆè¿›é™¢çš„å›¢é˜Ÿï¼Œè®ºæ–‡å‡ºå¤„[1]: Wang, Limin, et al. "Videomae v2:Scaling video masked autoencoders with dual masking." Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition.2023.</p></blockquote><h3 id="æ€»ç»“">æ€»ç»“ï¼š</h3><p>ä»¥ä¸‹ â€œæˆ‘ä»¬â€æŒ‡ä½œè€…</p><span id="more"></span><ol type="1"><li><p>åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šé¢„è®­ç»ƒçš„å¤§åŸºç¡€æ¨¡å‹æ­£åœ¨æˆä¸ºå­¦ä¹ å¤šæ•°æ®æ¨¡æ€é€šç”¨è¡¨å¾çš„æˆåŠŸèŒƒå¼ã€‚åŸºç¡€æ¨¡å‹å¯ä»¥å¾ˆå®¹æ˜“åœ°é€šè¿‡zero-shotã€linearprobeã€prompt tuningã€fine tuningåº”ç”¨åˆ°å¹¿æ³›çš„ä¸‹æ¸¸ä»»åŠ¡ï¼ˆ<strong>é‚£èƒ½å¤Ÿè¿™ä¹ˆå¹¿æ³›åœ°åº”ç”¨åˆ°ä¸‹æ¸¸ä»»åŠ¡ï¼Œæ˜¯æ•°æ®é‡å¤§çš„åŸå› å‘¢å æ¯”å¤šä¸€äº›å‘¢è¿˜æ˜¯æ¨¡å‹æ¯”è¾ƒå¥½çš„åŸå› å¤šä¸€äº›</strong>ï¼‰ã€‚Transformerwith masked autoencodingæ˜¯æœ‰æ•ˆçš„è‡ªç›‘ç£è§†è§‰å­¦ä¹ å™¨ã€‚æˆ‘ä»¬å°†VideoMAEåŒæ—¶åœ¨æ¨¡å‹å’Œæ•°æ®ä¸Šæ‰©å±•ï¼šç”¨ViT-g(Transformer with billion-level parameters)åˆå§‹åŒ–æ¨¡å‹ï¼›å°†æ•°æ®é›†çš„sizeå¢åŠ åˆ°million-levelã€‚</p></li><li><p>é¢ä¸´çš„é—®é¢˜ï¼š</p></li></ol><ul><li>æ‰©å±•VideoMAEéå¸¸è€—GPUå†…å­˜å’Œè®¡ç®—èµ„æºã€‚ä¸ºäº†æé«˜é¢„è®­ç»ƒæ•ˆç‡ï¼šå¤„ç†æ•°æ®å†—ä½™ï¼š1)åœ¨encoderä¸­maské«˜æ¯”ä¾‹çš„cubesï¼Œ2) åœ¨decoderä¸­drop some cubesã€‚</li><li>MAEå¯¹å¤§é‡çš„æ•°æ®éœ€æ±‚å¾ˆå¤§ã€‚ç°æœ‰çš„è§†é¢‘æ•°æ®ç›¸æ¯”äºå›¾åƒæ•°æ®çš„é‡çº§ï¼Œè¦å°‘å¾ˆå¤šã€‚æˆ‘ä»¬ç®€å•åœ°å°†å¤šä¸ªæ¥æºçš„æ•°æ®mixï¼Œæ¥ä¸ºVideoMAEåšé¢„è®­ç»ƒã€‚pre-trainingon million-level unlabeled video dataset and then post-pre-training onthe labeled hybrid datasetã€‚</li></ul><ol start="3" type="1"><li><p>è§†è§‰åŸºç¡€æ¨¡å‹ï¼š ä»æ—©æœŸçš„CNN ------&gt; Transformer -------&gt;BEiT, SimMIM, MAEã€‚vision-languange pre-trained model: CLIP,ALIGNã€‚è¿‘æœŸçš„å·¥ä½œå°è¯•ç”¨å¯¹æ¯”å­¦ä¹  Contrastive Learningã€SiameseLearningæ¥åšæ— ç›‘ç£å­¦ä¹ ã€‚è¿™äº›è§†è§‰åŸºç¡€æ¨¡å‹åœ¨zero-shotè¿ç§»ä¸Šå±•ç¤ºå‡ºäº†è‰¯å¥½çš„æ€§èƒ½ã€‚</p></li><li><p>VideoMAE</p><ol type="1"><li>three core components:</li></ol><ul><li>cube embedding: cube embedding encodes the local spatio-temporalfeatures and builds the token list</li><li>encoder: operates on unmasked tokens <spanclass="math inline">\(T^u\)</span> with a æ™®é€šçš„æ—¶ç©ºæ³¨æ„åŠ›çš„ViT.</li><li>decoder: å°†combined tokens <span class="math inline">\(Z^c\)</span>ä½œä¸ºè¾“å…¥ï¼Œç”¨å¦ä¸€ä¸ªViTè¿›è¡Œé‡å»ºï¼Œ <span class="math display">\[ \hat{I} =\Phi_{dec} (Z^{c}) \]</span></li><li>losss function: MSE: mean square error between masked pixels and thereconstructed pixelsã€‚</li></ul><ol start="2" type="1"><li>encoder-decoderéå¯¹ç§°ï¼Œencoderè¦å°ä¸€äº›ã€‚å°†VideoMAEæ‰©å±•åˆ°billion-levelæ—¶ï¼Œæ•´ä½“çš„è®¡ç®—é‡å’Œå­˜å‚¨é‡æ¶ˆè€—å°±æˆäº†ç“¶é¢ˆã€‚</li></ol></li><li><p>Dual Masking for VideoMAE:</p><ol type="1"><li>ä¸VideoMAEçš„ä¸åŒä¹‹å¤„åœ¨äºï¼šdecoderçš„è¾“å…¥æ¥è‡ªencoder visible tokensand part of the remaining tokens visible under the decoder mask <spanclass="math inline">\(M_d\)</span>ã€‚ç”¨decodermaskæ¥é™ä½decoderçš„è¾“å…¥çš„é•¿åº¦ for high efficiencyã€‚</li><li>encoderè¯•å›¾å»ç¼“è§£æ—¶åºå…³è”é€ æˆçš„information leakageï¼›è€Œåœ¨decodermaskingä¸­ï¼Œencourage information complementï¼Œæ¥ç¡®ä¿partialreconstruction information lossæœ€å°ï¼›å°½å¯èƒ½é€‰æ‹©diverse cubes æ¥coveræ•´ä¸ªè§†é¢‘ä¿¡æ¯ -----&gt; é‡‡ç”¨running cell maskingçš„ç­–ç•¥ã€‚</li></ol></li><li><p>Scaling VideoMAE:</p><ol type="1"><li>encoderé‡‡ç”¨ä¸åŒçš„backbones: ViT-B,ViT-L, ViT-H,ViT-gã€‚decoderå°±ç›¸å¯¹shallowå’Œlightweightï¼šç”¨æ›´å°‘çš„layerså’Œchannelsã€‚</li><li>å¼„äº†ä¸€ä¸ªunlabeled hybridè§†é¢‘æ•°æ®é›†ï¼Œçº¦1.3M clipsã€‚</li><li>Progressive training: å…ˆåœ¨æ— æ ‡ç­¾çš„hybrid videodatasetä¸Šç”¨MAEåšæ— ç›‘ç£é¢„è®­ç»ƒï¼›ç„¶åå»ºäº†ä¸€ä¸ªlabeled hybrid video dataset,å¯¹å…¶åšpost-pre-trainingã€‚æœ€ååœ¨ç›®æ ‡æ•°æ®é›†ä¸Šåšfine-tuningï¼Œå°†é€šç”¨è¯­ä¹‰è¿ç§»åˆ°task-centricknowledgeä¸Šã€‚</li></ol></li></ol><figure><imgsrc="https://d3i71xaburhd42.cloudfront.net/9fac3d0728a8c833a593446e3e176e90d856df04/1-Figure1-1.png"alt="VideoMAE with Dual Masking" /><figcaption aria-hidden="true">VideoMAE with Dual Masking</figcaption></figure><blockquote><p><span class="math inline">\(Figure\ 1^{[1]}\)</span>. <em>VideoMAEwith dual masking</em>. To improve the overall efficiency of computationand memory in video masked autoencoding, we propose to mask the decoderas well and devise the dual masking strategy. Like encoder, we alsoapply a masking map to the deocoder and simply reconstruct a subset ofpixel cubes selected by the running cell masking. The finalreconstruction loss only applies for the invisible tokens dropped by theencoder</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h3
id=&quot;videomae-v2-scaling-video-masked-autoencoders-with-dual-masking1&quot;&gt;&lt;span
class=&quot;math inline&quot;&gt;&#92;(VideoMAE&#92; v2: Scaling&#92; Video&#92; Masked&#92;
Autoencoders&#92; with&#92; Dual&#92; Masking^{[1]}&#92;)&lt;/span&gt; ğŸï¸&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;ä½œè€…ä»¬æ˜¯æ¥è‡ªå—å¤§ Novel Software Technology Labã€ä¸Šæµ·AI
Labå’Œæ·±åœ³å…ˆè¿›é™¢çš„å›¢é˜Ÿï¼Œè®ºæ–‡å‡ºå¤„[1]: Wang, Limin, et al. &quot;Videomae v2:
Scaling video masked autoencoders with dual masking.&quot; Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition.
2023.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;æ€»ç»“&quot;&gt;æ€»ç»“ï¼š&lt;/h3&gt;
&lt;p&gt;ä»¥ä¸‹ â€œæˆ‘ä»¬â€æŒ‡ä½œè€…&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="https://young-eng.github.io/YoungBlogs/categories/Papers/"/>
    
    
    <category term="Video Understanding" scheme="https://young-eng.github.io/YoungBlogs/tags/Video-Understanding/"/>
    
  </entry>
  
  <entry>
    <title>YOLO</title>
    <link href="https://young-eng.github.io/YoungBlogs/2024/01/24/YOLO/"/>
    <id>https://young-eng.github.io/YoungBlogs/2024/01/24/YOLO/</id>
    <published>2024-01-24T15:25:08.000Z</published>
    <updated>2024-01-26T13:38:58.409Z</updated>
    
    <content type="html"><![CDATA[<h2 id="yolo-ç³»åˆ—è®ºæ–‡">YOLO ç³»åˆ—è®ºæ–‡</h2><p>å¼€å¤´è¯´å‡ å¥é¢˜å¤–è¯ï¼šè¿™å‡ å¤©æƒ³äº†æƒ³ï¼Œæ‰“ç®—ç”¨Blogæ¥è®°å½•ä¸€ä¸‹çœ‹åˆ°çš„è®ºæ–‡ï¼Œç»™è‡ªå·±ä¸€ä¸ªç£ä¿ƒã€‚ç°åœ¨AIå‘å±•æ—¥æ–°æœˆå¼‚ï¼Œå°¤å…¶æ˜¯ChatGPTå‡ºæ¥ä¹‹åï¼Œå„ç§æ–°çš„è®ºæ–‡å¤ªå¤šäº†ï¼Œéƒ½ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹çœ‹ï¼Œæœ‰ç‚¹çœ¼èŠ±ç¼­ä¹±ï¼Œæ€æ¥æƒ³å»ï¼Œè¿˜æ˜¯ä¸€æ­¥ä¸€æ­¥æ¥ï¼Œä»ç»å…¸è®ºæ–‡å¼€å§‹ï¼Œå½“ç„¶ä¹Ÿä¼šçœ‹æ–°çš„çƒ­åº¦å¾ˆé«˜çš„è®ºæ–‡ï¼Œé€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¥ä¸€ç‚¹ä¸€ç‚¹çš„è¿›æ­¥å§ã€‚ä¸ç§¯è·¬æ­¥æ— ä»¥è‡³åƒé‡Œï¼›åƒé‡Œä¹‹è¡Œï¼Œå§‹äºè¶³ä¸‹ã€‚åŠ æ²¹ï¼ï¼ï¼åªè¦æƒ³åšï¼Œä»€ä¹ˆæ—¶å€™éƒ½ä¸ç®—æ™šï¼ï¼ğŸƒ</p><h3 id="you-only-look-once-unified-real-time-object-detection1"><spanclass="math inline">\(You\ Only\ Look\ Once: Unified, Real-Time\ Object\Detection^{[1]}\)</span>ğŸš€</h3><blockquote><p>ä½œè€…æ˜¯æ¥è‡ªU of Washingtonã€Allen Institute for AIå’ŒFAIR,åŒ…æ‹¬JosephRedmonã€Santosh Divvalalaã€Ross Girshick ç­‰ã€‚è®ºæ–‡å‡ºå¤„ï¼š[1]Redmon, Josephet al. â€œYou Only Look Once: Unified, Real-Time Object Detection.â€ 2016IEEE Conference on Computer Vision and Pattern Recognition (CVPR)(2015): 779-788.</p></blockquote><h3 id="æ€»ç»“">æ€»ç»“ï¼š</h3><span id="more"></span><p>ä»¥ä¸‹â€œæˆ‘ä»¬â€ä»£æŒ‡ä½œè€…</p><ol type="1"><li><p>å…ˆå‰çš„å·¥ä½œæ˜¯ç”¨åˆ†ç±»å™¨æ¥åšæ£€æµ‹ï¼›æˆ‘ä»¬å°†ç›®æ ‡æ£€æµ‹è§†ä¸ºç©ºé—´ä¸Šåˆ†éš”çš„bboxeså’Œç›¸å…³è”çš„ç±»åˆ«æ¦‚ç‡çš„å›å½’é—®é¢˜ã€‚ä¸€ä¸ªå•ä¸€çš„ç¥ç»ç½‘ç»œä»æ•´ä¸ªå›¾åƒé‡Œï¼Œåœ¨ä¸€æ¬¡evaluationé‡Œï¼Œç›´æ¥é¢„æµ‹bboxeså’Œå¯¹åº”çš„ç±»åˆ«æ¦‚ç‡ã€‚pipelineæ˜¯å•ä¸ªç½‘ç»œï¼Œå¯ä»¥å†æ£€æµ‹æ€§èƒ½ä¸Šä¼˜åŒ–ä¸ºç«¯åˆ°ç«¯çš„ã€‚é€Ÿåº¦éå¸¸å¿«ï¼Œä½†æ˜¯å®šä½ä¹Ÿæœ‰å¾ˆå¤šé”™è¯¯ã€‚</p></li><li><p>åœ¨è®­ç»ƒå’Œæµ‹è¯•æ—¶ï¼Œèƒ½çœ‹åˆ°å…¨å±€çš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå¯¹ä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œç¼–ç ï¼ŒFastR-CNNçœ‹ä¸åˆ°å¤§çš„ä¸Šä¸‹æ–‡ï¼›åœ¨æ³›åŒ–æ€§ä¸Šï¼ŒYOLOè¦å¥½ä¸€äº›ã€‚Trade-off:é€Ÿåº¦å¿«ï¼Œä½†æ˜¯ç²¾ç¡®å®šä½ç‰©ä½“ç‰¹åˆ«æ˜¯å°ç›®æ ‡ï¼Œæœ‰è¯¯å·®ã€‚</p></li><li><p>å°†è¾“å…¥å›¾åƒç”Ÿæˆ <span class="math inline">\(S \times S\)</span>çš„Gridsï¼Œæ¯ä¸ªGridé¢„æµ‹ <span class="math inline">\(B\)</span>ä¸ªbboxeså’Œç½®ä¿¡åº¦ï¼ŒåŒ…æ‹¬5ä¸ªå‚æ•°: <spanclass="math inline">\(x,y,w,h,p_c\)</span>ã€‚æ¯ä¸ªGridé¢„æµ‹Cä¸ªç±»çš„æ¡ä»¶æ¦‚ç‡ã€‚</p></li><li><p>YOLO: 24å±‚å·ç§¯ç½‘ç»œï¼Œ2ä¸ªå…¨è¿æ¥å±‚ï¼Œè¾“å…¥å›¾åƒå¤§å°ä¸º<spanclass="math inline">\(448\times448\)</span>,æœ€åè¾“å‡º <spanclass="math inline">\(7\times7\times30\)</span>ï¼› Fast YOLOï¼š9ä¸ªå·ç§¯å±‚ï¼Œç”¨Sum-squared Erroræ¥è¿›è¡Œä¼˜åŒ–ï¼ŒLimitations:æ¯ä¸ªGridé¢„æµ‹2ä¸ªbboxesï¼Œé™åˆ¶äº†é‚»è¿‘ç‰©ä½“çš„æ•°é‡ã€‚LossFunctionä¸­ï¼ŒåŒç­‰å¯¹å¾…å¤§bboxeså’Œå°bboxesçš„errorsï¼Œç„¶è€Œä¸€ä¸ªå°çš„é”™è¯¯åœ¨å¤§çš„boxeså’Œå°çš„boxesä¸­çš„å½±å“ä¸åŒã€‚</p></li></ol><figure><imgsrc="https://d3i71xaburhd42.cloudfront.net/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png"alt="YOLO Architecture^[1]" /><figcaption aria-hidden="true"><span class="math inline">\(YOLOArchitecture^[1]\)</span></figcaption></figure><blockquote><p><span class="math inline">\(Figure\ 1^{[1]}\)</span>: <em>TheArchitecture</em>. Our detection network has 24 convolutional layersfollowed by 2 fully connected layers. Alternating 1Ã— 1 convolutionallayers reduce the features space from preceding layers. We pretrain theconvolutional layers on the ImageNet classification task at half theresolution (224Ã— 224 input image) and then double the resolution fordetectionã€‚</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;yolo-ç³»åˆ—è®ºæ–‡&quot;&gt;YOLO ç³»åˆ—è®ºæ–‡&lt;/h2&gt;
&lt;p&gt;å¼€å¤´è¯´å‡ å¥é¢˜å¤–è¯ï¼šè¿™å‡ å¤©æƒ³äº†æƒ³ï¼Œæ‰“ç®—ç”¨Blogæ¥è®°å½•ä¸€ä¸‹çœ‹åˆ°çš„è®ºæ–‡ï¼Œç»™è‡ªå·±ä¸€ä¸ªç£ä¿ƒã€‚ç°åœ¨AIå‘å±•æ—¥æ–°æœˆå¼‚ï¼Œå°¤å…¶æ˜¯ChatGPTå‡ºæ¥ä¹‹åï¼Œå„ç§æ–°çš„è®ºæ–‡å¤ªå¤šäº†ï¼Œéƒ½ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹çœ‹ï¼Œæœ‰ç‚¹çœ¼èŠ±ç¼­ä¹±ï¼Œæ€æ¥æƒ³å»ï¼Œè¿˜æ˜¯ä¸€æ­¥ä¸€æ­¥æ¥ï¼Œä»ç»å…¸è®ºæ–‡å¼€å§‹ï¼Œå½“ç„¶ä¹Ÿä¼šçœ‹æ–°çš„çƒ­åº¦å¾ˆé«˜çš„è®ºæ–‡ï¼Œé€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¥ä¸€ç‚¹ä¸€ç‚¹çš„è¿›æ­¥å§ã€‚ä¸ç§¯è·¬æ­¥æ— ä»¥è‡³åƒé‡Œï¼›åƒé‡Œä¹‹è¡Œï¼Œå§‹äºè¶³ä¸‹ã€‚åŠ æ²¹ï¼ï¼ï¼åªè¦æƒ³åšï¼Œä»€ä¹ˆæ—¶å€™éƒ½ä¸ç®—æ™šï¼ï¼ğŸƒ&lt;/p&gt;
&lt;h3 id=&quot;you-only-look-once-unified-real-time-object-detection1&quot;&gt;&lt;span
class=&quot;math inline&quot;&gt;&#92;(You&#92; Only&#92; Look&#92; Once: Unified, Real-Time&#92; Object&#92;
Detection^{[1]}&#92;)&lt;/span&gt;ğŸš€&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;ä½œè€…æ˜¯æ¥è‡ªU of Washingtonã€Allen Institute for AIå’ŒFAIR,åŒ…æ‹¬Joseph
Redmonã€Santosh Divvalalaã€Ross Girshick ç­‰ã€‚è®ºæ–‡å‡ºå¤„ï¼š[1]Redmon, Joseph
et al. â€œYou Only Look Once: Unified, Real-Time Object Detection.â€ 2016
IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
(2015): 779-788.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;æ€»ç»“&quot;&gt;æ€»ç»“ï¼š&lt;/h3&gt;</summary>
    
    
    
    <category term="Papers" scheme="https://young-eng.github.io/YoungBlogs/categories/Papers/"/>
    
    
    <category term="Object Detection" scheme="https://young-eng.github.io/YoungBlogs/tags/Object-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://young-eng.github.io/YoungBlogs/2024/01/24/hello-world/"/>
    <id>https://young-eng.github.io/YoungBlogs/2024/01/24/hello-world/</id>
    <published>2024-01-24T14:44:26.662Z</published>
    <updated>2023-11-14T12:23:10.800Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your veryfirst post. Check <a href="https://hexo.io/docs/">documentation</a> formore info. If you get any problems when using Hexo, you can find theanswer in <ahref="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> oryou can ask me on <ahref="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><span id="more"></span><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very
first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for
more info. If you get any problems when using Hexo, you can find the
answer in &lt;a
href=&quot;https://hexo.io/docs/troubleshooting.html&quot;&gt;troubleshooting&lt;/a&gt; or
you can ask me on &lt;a
href=&quot;https://github.com/hexojs/hexo/issues&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>sshKey</title>
    <link href="https://young-eng.github.io/YoungBlogs/2024/01/22/sshKey/"/>
    <id>https://young-eng.github.io/YoungBlogs/2024/01/22/sshKey/</id>
    <published>2024-01-21T16:21:33.000Z</published>
    <updated>2024-01-22T08:16:24.538Z</updated>
    
    <content type="html"><![CDATA[<h3 id="sshkey-è®°å½•">sshKey è®°å½•</h3><p>ä»Šå¤©ä¼ ä»£ç çš„æ—¶å€™ï¼Œå‘ç°ä¸€ç›´æŠ¥è¿æ¥è¶…æ—¶ï¼Œkex_exchange_identification:Connection closed by remote hostï¼ŒPlease make sure you have the correctaccess rights and the repository exists.çªç„¶åˆéƒé—·äº†ã€‚æœäº†ä¸€åœˆä¹‹åï¼Œå‘ç°å¥½åƒæ˜¯è¿œç¨‹å¯†é’¥çš„é—®é¢˜ã€‚åœ¨å‡ºç°Are you surewant to continue connecting (yes/no/[fingerprint])?çš„æ—¶å€™ï¼Œè¾“å…¥yesï¼Œç„¶åå°±OKäº†ã€‚</p><span id="more"></span><h4 id="ssh-ç”Ÿæˆå…¬é’¥çš„å‘½ä»¤">ssh ç”Ÿæˆå…¬é’¥çš„å‘½ä»¤</h4><ul><li>ssh-keygen -t rsa -C "GitHubè´¦å·çš„æ³¨å†Œé‚®ç®±"</li></ul><p>ä¸€èˆ¬æ˜¯åœ¨ ~\username\.sshç›®å½•ä¸‹ã€‚å°†id_rsa.pubé‡Œçš„å†…å®¹å¤åˆ¶åˆ°githubçš„ssh keyé‡Œã€‚</p><ul><li>åœ¨ ~\username\.sshç›®å½•ä¸‹ï¼Œæ–°å»ºä¸€ä¸ªconfigæ–‡ä»¶ï¼Œå°†ä¸€ä¸‹å†…å®¹å¤åˆ¶è¿›å»ï¼Œè§£å†³äº†è¶…æ—¶çš„é—®é¢˜ï¼š</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Host github.com</span><br><span class="line"></span><br><span class="line">Hostname ssh.github.com</span><br><span class="line"></span><br><span class="line">Port 443</span><br><span class="line"></span><br><span class="line">User git</span><br></pre></td></tr></table></figure><h4 id="å‚è€ƒé“¾æ¥">å‚è€ƒé“¾æ¥</h4><p>https://github.com/orgs/community/discussions/55269</p><p>https://www.cnblogs.com/gosun/p/13044672.html</p><p>https://stackoverflow.com/questions/11443687/the-authenticity-of-host-cant-be-established</p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;sshkey-è®°å½•&quot;&gt;sshKey è®°å½•&lt;/h3&gt;
&lt;p&gt;ä»Šå¤©ä¼ ä»£ç çš„æ—¶å€™ï¼Œå‘ç°ä¸€ç›´æŠ¥è¿æ¥è¶…æ—¶ï¼Œkex_exchange_identification:
Connection closed by remote hostï¼ŒPlease make sure you have the correct
access rights and the repository exists.
çªç„¶åˆéƒé—·äº†ã€‚æœäº†ä¸€åœˆä¹‹åï¼Œå‘ç°å¥½åƒæ˜¯è¿œç¨‹å¯†é’¥çš„é—®é¢˜ã€‚åœ¨å‡ºç°Are you sure
want to continue connecting (yes/no/[fingerprint])?
çš„æ—¶å€™ï¼Œè¾“å…¥yesï¼Œç„¶åå°±OKäº†ã€‚&lt;/p&gt;</summary>
    
    
    
    <category term="Tools" scheme="https://young-eng.github.io/YoungBlogs/categories/Tools/"/>
    
    
    <category term="Git" scheme="https://young-eng.github.io/YoungBlogs/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>Deployblogs</title>
    <link href="https://young-eng.github.io/YoungBlogs/2023/12/28/Deployblogs/"/>
    <id>https://young-eng.github.io/YoungBlogs/2023/12/28/Deployblogs/</id>
    <published>2023-12-28T15:10:20.000Z</published>
    <updated>2023-12-29T06:47:29.636Z</updated>
    
    <content type="html"><![CDATA[<h3 id="éƒ¨ç½²åšå®¢æ–¹å¼">éƒ¨ç½²åšå®¢æ–¹å¼</h3><ol type="1"><li>éƒ¨ç½²åœ¨ Vercel,Netlify è¿™æ ·çš„å…è´¹å¹³å°ä¸Š</li><li>éƒ¨ç½²åœ¨ Github Pages ä¸Š,æ˜¯ç”¨gh-pagesåˆ†æ”¯æ¥éƒ¨ç½²çš„ï¼Œxxx.github.ioå¯ä»¥ç”¨æ¥åšä¸ªäººä¸»é¡µä»‹ç»ï¼Œgh-pagesç”¨æ¥åšåšå®¢</li></ol><h4 id="éƒ¨ç½²åœ¨-vercel-ä¸Šçš„åšå®¢">éƒ¨ç½²åœ¨ Vercel ä¸Šçš„åšå®¢</h4><ol type="1"><li><p>å¯ä»¥é€šè¿‡å’Œgithubè´¦å·å…³è”ï¼Œä¸€é”®éƒ¨ç½²ï¼Œå¾ˆæ–¹ä¾¿</p></li><li><p>åœ¨æœ¬åœ°å®‰è£…vercelï¼Œ é€šè¿‡vercelçš„å‘½ä»¤è¡Œå·¥å…·ï¼Œæ¥å®ç°éƒ¨ç½²</p></li><li><p>é‡åˆ°çš„é—®é¢˜ï¼Œvercelæ˜“è¢«DNSæ±¡æŸ“ï¼Œæ­£å¸¸è®¿é—®æ‰“ä¸å¼€ï¼Œçœ‹åˆ°æœ‰å¸–å­è¯´å¯ä»¥ä¹°ä¸ªåŸŸåå¼„ä¸€ä¸‹ï¼Œæœ‰é’±äº†å†ä¹°ä¸ªåŸŸåç©ä¸€ç©,ğŸ˜­</p></li></ol><span id="more"></span><h4 id="éƒ¨ç½²åœ¨-github-pagesä¸Š">éƒ¨ç½²åœ¨ Github Pagesä¸Š</h4><ol type="1"><li>å…ˆè¦åˆ›å»ºä¸€ä¸ªrepo,ç„¶åå»ºç«‹ä¸€ä¸ªgh-pagesåˆ†æ”¯ï¼Œç„¶åæŠŠåšå®¢ä»£ç pushåˆ°gh-pagesåˆ†æ”¯ä¸Šï¼Œç„¶åé€šè¿‡åŸŸåè®¿é—®åšå®¢ï¼Œéœ€è¦å»settingé‡Œæ”¹ä¸€ä¸‹branchå’Œsourceï¼Œç„¶ååœ¨__config.ymlé‡Œï¼Œdeployçš„è®¾ç½®éœ€è¦ä¿®æ”¹ï¼ŒåŒ…æ‹¬type,repoå’Œbranchï¼Œ branch:gh-pagesï¼Œå¦å¤–è¿˜æœ‰ä¸€ä¸ªurléœ€è¦ä¿®æ”¹ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå¤§å‘ï¼Œå¥½ä¸å®¹æ˜“èƒ½æ‰“å¼€blogsç½‘å€äº†ï¼Œå‘ç°é¡µé¢æ²¡æœ‰æ¸²æŸ“ï¼Œurléœ€è¦æ”¹ä¸ºxxx.github.io/xxxï¼Œç„¶åroot:/xxx/ï¼Œè¿™æ ·å°±èƒ½æ­£å¸¸è®¿é—®äº†ï¼Œéœ€è¦hexo generateä¸€ä¸‹ï¼Œç„¶åhexodeployä¸€ä¸‹ï¼Œæ‰èƒ½çœ‹åˆ°æ•ˆæœã€‚</li></ol><p>å‚è€ƒé“¾æ¥å¦‚ä¸‹ï¼š</p><p>https://cloud.tencent.com/developer/article/1391619</p><p>https://einverne.github.io/gitbook-tutorial/publish/gitpages.html</p><p>https://blog.csdn.net/qq_58832911/article/details/128028317</p><p>https://www.cnblogs.com/xuyiyang/p/13647069.html</p><p>https://www.xxyopen.com/2022/07/19/tools/pages_host.html</p><p>https://blog.csdn.net/qq_44960878/article/details/131548656</p><p>https://blog.csdn.net/m0_57236802/article/details/134333457</p><p>https://sinoui.github.io/sinoui-guide/docs/github-pages-introduction</p><p>https://blog.csdn.net/banjw_129/article/details/82261165</p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;éƒ¨ç½²åšå®¢æ–¹å¼&quot;&gt;éƒ¨ç½²åšå®¢æ–¹å¼&lt;/h3&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;éƒ¨ç½²åœ¨ Vercel,Netlify è¿™æ ·çš„å…è´¹å¹³å°ä¸Š&lt;/li&gt;
&lt;li&gt;éƒ¨ç½²åœ¨ Github Pages ä¸Š,
æ˜¯ç”¨gh-pagesåˆ†æ”¯æ¥éƒ¨ç½²çš„ï¼Œxxx.github.ioå¯ä»¥ç”¨æ¥åšä¸ªäººä¸»é¡µä»‹ç»ï¼Œgh-pagesç”¨æ¥åšåšå®¢&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;éƒ¨ç½²åœ¨-vercel-ä¸Šçš„åšå®¢&quot;&gt;éƒ¨ç½²åœ¨ Vercel ä¸Šçš„åšå®¢&lt;/h4&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;å¯ä»¥é€šè¿‡å’Œgithubè´¦å·å…³è”ï¼Œä¸€é”®éƒ¨ç½²ï¼Œå¾ˆæ–¹ä¾¿&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;åœ¨æœ¬åœ°å®‰è£…vercelï¼Œ é€šè¿‡vercelçš„å‘½ä»¤è¡Œå·¥å…·ï¼Œæ¥å®ç°éƒ¨ç½²&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;é‡åˆ°çš„é—®é¢˜ï¼Œvercelæ˜“è¢«DNSæ±¡æŸ“ï¼Œæ­£å¸¸è®¿é—®æ‰“ä¸å¼€ï¼Œçœ‹åˆ°æœ‰å¸–å­è¯´å¯ä»¥ä¹°ä¸ªåŸŸåå¼„ä¸€ä¸‹ï¼Œæœ‰é’±äº†å†ä¹°ä¸ªåŸŸåç©ä¸€ç©,
ğŸ˜­&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Tools" scheme="https://young-eng.github.io/YoungBlogs/categories/Tools/"/>
    
    
    <category term="blog" scheme="https://young-eng.github.io/YoungBlogs/tags/blog/"/>
    
  </entry>
  
  <entry>
    <title>UseGit</title>
    <link href="https://young-eng.github.io/YoungBlogs/2023/12/09/UseGit/"/>
    <id>https://young-eng.github.io/YoungBlogs/2023/12/09/UseGit/</id>
    <published>2023-12-09T11:36:04.000Z</published>
    <updated>2024-01-21T16:47:40.016Z</updated>
    
    <content type="html"><![CDATA[<h3id="è¶ç€è¿™ä¸ªè®¡ç®—ç¥ç»ç§‘å­¦çš„è¯¾ç”¨ä¸€ç”¨git">è¶ç€è¿™ä¸ªè®¡ç®—ç¥ç»ç§‘å­¦çš„è¯¾ï¼Œç”¨ä¸€ç”¨git</h3><p>ä¸»è¦çš„æµç¨‹æ˜¯ï¼š</p><ul><li><code>git init</code> åˆå§‹åŒ–</li><li><code>git add .</code> åŠ è½½æ‰€æœ‰æ–‡ä»¶</li><li><code>git commit -m "first commit"</code></li><li><code>git branch -M main</code> å°†ä¸»åˆ†æ”¯åå­—ç”±master æ”¹ä¸ºmain</li><li><code>git remote add origin github.com/xxx/xxx.git</code>åé¢çš„è¿™ä¸ªé“¾æ¥åå­—æ¢æˆäº† origin</li><li><code>git push -u origin main</code> ä¼ åˆ°originçš„mainåˆ†æ”¯ä¸Š,ç”¨è¿™ä¸ªå‘½ä»¤ä¹Ÿè¡Œï¼Œ<code>git push --set-upstream origin xxx</code></li></ul><p>å¦‚æœä»£ç æˆ–è€…æ–‡ä»¶æœ‰ä¿®æ”¹ï¼Œå¯ä»¥ç”¨git status æŸ¥çœ‹æ”¹åŠ¨çš„æ–‡ä»¶ï¼Œç”¨git add<filename> æ·»åŠ æ–‡ä»¶åˆ°ç¼“å­˜åŒºï¼Œgit add . æ˜¯ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰æ–‡ä»¶ï¼Œç„¶å<code>git commit -m "first commit"</code> æäº¤åˆ°æœ¬åœ°ä»“åº“ï¼Œgit pushæäº¤åˆ°è¿œç¨‹ä»“åº“ã€‚</p><span id="more"></span><p>å¦‚æœè¦åˆå¹¶åˆ†æ”¯çš„è¯ï¼Œç”¨<code>git pull origin main --allow-unrelated-histories</code>ï¼Œç„¶åå†<code>git push origin main</code>æ¨é€åˆ°è¿œç¨‹ã€‚</p><p>å¦‚æœè¦åˆ é™¤è¿œç¨‹ä»“åº“æ–‡ä»¶/æ–‡ä»¶å¤¹ï¼Œç”¨<code>git rm -r --cached &lt;filename&gt;</code>åˆ é™¤æ–‡ä»¶å¤¹ï¼Œç”¨<code>git rm --cached &lt;filename&gt;</code>åˆ é™¤æ–‡ä»¶ï¼Œä¸å†™--cached çš„è¯ï¼Œä¼šç›´æ¥åˆ é™¤æœ¬åœ°æ–‡ä»¶å¤¹ã€‚</p><p>å¤§æ–‡ä»¶ï¼Œè¶…è¿‡100Mçš„ï¼Œç”¨git lfs å‘½ä»¤ï¼Œ</p><p><code>git lfs track xxx</code></p><p><code>git add xxxx</code></p><p><code>git commit -m "xxx"</code></p><p><code>git push</code></p><p>åˆ é™¤git commit ä¸­çš„å¤§æ–‡ä»¶</p><p><code>git cherry -v</code> <code>git reset commit_id</code></p><p>ä¸‰ç§æ–¹æ³•è§£å†³ fatal: remote origin already exists.</p><p>https://blog.csdn.net/qq_34769162/article/details/116379638</p><p>å‚è€ƒé“¾æ¥ï¼š</p><p>https://www.jianshu.com/p/46489723fc5f</p><p>https://blog.csdn.net/weixin_42693712/article/details/108326096</p><p>https://zhuanlan.zhihu.com/p/624993960</p><p>https://git-lfs.com/</p><p>https://blog.csdn.net/dappp3000/article/details/111321738</p><p>https://docs.github.com/zh/repositories/configuring-branches-and-merges-in-your-repository/managing-branches-in-your-repository/renaming-a-branch</p><p>https://blog.csdn.net/faihung/article/details/96273705</p>]]></content>
    
    
    <summary type="html">&lt;h3
id=&quot;è¶ç€è¿™ä¸ªè®¡ç®—ç¥ç»ç§‘å­¦çš„è¯¾ç”¨ä¸€ç”¨git&quot;&gt;è¶ç€è¿™ä¸ªè®¡ç®—ç¥ç»ç§‘å­¦çš„è¯¾ï¼Œç”¨ä¸€ç”¨git&lt;/h3&gt;
&lt;p&gt;ä¸»è¦çš„æµç¨‹æ˜¯ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git init&lt;/code&gt; åˆå§‹åŒ–&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git add .&lt;/code&gt; åŠ è½½æ‰€æœ‰æ–‡ä»¶&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git commit -m &quot;first commit&quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git branch -M main&lt;/code&gt; å°†ä¸»åˆ†æ”¯åå­—ç”±master æ”¹ä¸ºmain&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git remote add origin github.com/xxx/xxx.git&lt;/code&gt;
åé¢çš„è¿™ä¸ªé“¾æ¥åå­—æ¢æˆäº† origin&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git push -u origin main&lt;/code&gt; ä¼ åˆ°originçš„mainåˆ†æ”¯ä¸Š
,ç”¨è¿™ä¸ªå‘½ä»¤ä¹Ÿè¡Œï¼Œ&lt;code&gt;git push --set-upstream origin xxx&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å¦‚æœä»£ç æˆ–è€…æ–‡ä»¶æœ‰ä¿®æ”¹ï¼Œå¯ä»¥ç”¨git status æŸ¥çœ‹æ”¹åŠ¨çš„æ–‡ä»¶ï¼Œç”¨git add
&lt;filename&gt; æ·»åŠ æ–‡ä»¶åˆ°ç¼“å­˜åŒºï¼Œgit add . æ˜¯ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰æ–‡ä»¶ï¼Œç„¶å
&lt;code&gt;git commit -m &quot;first commit&quot;&lt;/code&gt; æäº¤åˆ°æœ¬åœ°ä»“åº“ï¼Œgit push
æäº¤åˆ°è¿œç¨‹ä»“åº“ã€‚&lt;/p&gt;</summary>
    
    
    
    <category term="Tools" scheme="https://young-eng.github.io/YoungBlogs/categories/Tools/"/>
    
    
    <category term="Git" scheme="https://young-eng.github.io/YoungBlogs/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>paintwithPython</title>
    <link href="https://young-eng.github.io/YoungBlogs/2023/11/27/paintwithPython/"/>
    <id>https://young-eng.github.io/YoungBlogs/2023/11/27/paintwithPython/</id>
    <published>2023-11-27T02:04:21.000Z</published>
    <updated>2023-11-27T02:05:19.592Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    
    <category term="Interests" scheme="https://young-eng.github.io/YoungBlogs/tags/Interests/"/>
    
  </entry>
  
  <entry>
    <title>transformer</title>
    <link href="https://young-eng.github.io/YoungBlogs/2023/11/24/transformer/"/>
    <id>https://young-eng.github.io/YoungBlogs/2023/11/24/transformer/</id>
    <published>2023-11-24T13:10:25.000Z</published>
    <updated>2023-11-25T03:40:18.471Z</updated>
    
    <content type="html"><![CDATA[<h3 id="transformer">Transformer</h3><p>ä¸¤ç§æ³¨æ„åŠ›è¯„åˆ†ï¼š åŠ æ€§æ³¨æ„åŠ›å’Œç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›</p><h4 id="å‘é‡åŒ–">å‘é‡åŒ–:</h4><p>Q ä¸ºnxdç»´ï¼ŒKä¸ºmxdç»´ï¼ŒVä¸ºmxvç»´ï¼Œn,mä¸ºqueryä¸ªæ•°å’Œé”®å€¼å¯¹çš„ä¸ªæ•°ã€‚d,vä¸ºå€¼çš„ç»´æ•°ã€‚</p><h4id="nnconv2då·ç§¯æ“ä½œçš„ç‰¹å¾å›¾çš„å°ºå¯¸è®¡ç®—">nnConv2då·ç§¯æ“ä½œçš„ç‰¹å¾å›¾çš„å°ºå¯¸è®¡ç®—</h4><p>ç»è¿‡å·ç§¯åçš„ç‰¹å¾å›¾å°ºå¯¸ç­‰äºå·ç§¯æ ¸æ»‘åŠ¨çš„æ¬¡æ•° +1ï¼Œç°åœ¨å‡è®¾å·ç§¯å‰çš„ç‰¹å¾å›¾å®½åº¦ä¸ºNï¼Œå·ç§¯åè¾“å‡ºçš„ç‰¹å¾å›¾å®½åº¦ä¸ºMï¼Œpaddingä¹‹åçš„çŸ©é˜µå®½åº¦ç­‰äºN+2*padding ã€‚å·ç§¯æ ¸çš„æ»‘åŠ¨æ¬¡æ•°ç­‰äº M-1</p><p><span class="math display">\[ N+2{\times}padding =(M-1){\times}strides +kernel\_size \]</span> è¾“å‡ºçŸ©é˜µçš„å®½åº¦</p><p><span class="math display">\[M = (N + 2* padding -kernel\_size)/stride + 1 \]</span></p><p>[çŸ¥ä¹é“¾æ¥]https://zhuanlan.zhihu.com/p/163017446</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;transformer&quot;&gt;Transformer&lt;/h3&gt;
&lt;p&gt;ä¸¤ç§æ³¨æ„åŠ›è¯„åˆ†ï¼š åŠ æ€§æ³¨æ„åŠ›å’Œç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›&lt;/p&gt;
&lt;h4 id=&quot;å‘é‡åŒ–&quot;&gt;å‘é‡åŒ–:&lt;/h4&gt;
&lt;p&gt;Q ä¸º
nxdç»´ï¼ŒKä¸ºmxdç»´ï¼ŒVä¸ºmxvç»´ï¼Œn,mä¸ºqueryä¸ªæ•°å’Œé”®å€¼å¯¹çš„ä¸ªæ•°ã€‚</summary>
      
    
    
    
    
    <category term="ç®—æ³•" scheme="https://young-eng.github.io/YoungBlogs/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Sleap_and_DeepLabCut</title>
    <link href="https://young-eng.github.io/YoungBlogs/2023/11/22/Sleap-and-DeepLabCut/"/>
    <id>https://young-eng.github.io/YoungBlogs/2023/11/22/Sleap-and-DeepLabCut/</id>
    <published>2023-11-22T01:44:33.000Z</published>
    <updated>2023-11-22T01:47:17.593Z</updated>
    
    <content type="html"><![CDATA[<h2 id="sleap">Sleap</h2><h3 id="train">Train</h3><p>sleap-train path/to/your/training_profile.jsonanother/path/to/labels.pkg.slp</p><h3 id="inference">Inference</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;sleap&quot;&gt;Sleap&lt;/h2&gt;
&lt;h3 id=&quot;train&quot;&gt;Train&lt;/h3&gt;
&lt;p&gt;sleap-train path/to/your/training_profile.json
another/path/to/labels.pkg.slp&lt;/p&gt;</summary>
      
    
    
    
    
    <category term="ç®—æ³•" scheme="https://young-eng.github.io/YoungBlogs/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Methods</title>
    <link href="https://young-eng.github.io/YoungBlogs/2023/11/19/Methods/"/>
    <id>https://young-eng.github.io/YoungBlogs/2023/11/19/Methods/</id>
    <published>2023-11-19T04:29:52.000Z</published>
    <updated>2024-02-20T11:56:59.432Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    <category term="Learning" scheme="https://young-eng.github.io/YoungBlogs/categories/Learning/"/>
    
    
    <category term="å­¦ä¹ æ–¹æ³•" scheme="https://young-eng.github.io/YoungBlogs/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>SVD</title>
    <link href="https://young-eng.github.io/YoungBlogs/2023/11/17/SVD/"/>
    <id>https://young-eng.github.io/YoungBlogs/2023/11/17/SVD/</id>
    <published>2023-11-17T07:07:36.000Z</published>
    <updated>2023-11-17T07:12:00.525Z</updated>
    
    <content type="html"><![CDATA[<p>å‚è€ƒé“¾æ¥ï¼šhttps://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htmè¿™ä¸ªé‡Œé¢æœ‰å‡ å¤„é”™è¯¯ï¼ŒAçš„è½¬ç½®çŸ©é˜µä¸å¯¹ã€‚</p><p>https://my.oschina.net/findbill/blog/535044</p><p>https://zhuanlan.zhihu.com/p/77151308</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;å‚è€ƒé“¾æ¥ï¼š
https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm
è¿™ä¸ªé‡Œé¢æœ‰å‡ å¤„é”™è¯¯ï¼ŒAçš„è½¬ç½®çŸ©é˜µä¸å¯¹ã€‚&lt;/p&gt;
&lt;p&gt;https://my.oschina.net/findbill/b</summary>
      
    
    
    
    <category term="math" scheme="https://young-eng.github.io/YoungBlogs/categories/math/"/>
    
    
    <category term="çº¿æ€§ä»£æ•°" scheme="https://young-eng.github.io/YoungBlogs/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>BuildHexo</title>
    <link href="https://young-eng.github.io/YoungBlogs/2023/11/13/BuildHexo/"/>
    <id>https://young-eng.github.io/YoungBlogs/2023/11/13/BuildHexo/</id>
    <published>2023-11-13T09:20:46.000Z</published>
    <updated>2023-12-29T06:52:14.826Z</updated>
    
    <content type="html"><![CDATA[<p>æœ€è¿‘ä¸€ç›´æœ‰ä¸ªæƒ³æ³•ï¼Œæƒ³å»å¼„ä¸ªåšå®¢ï¼Œä¹‹å‰æœ‰åœ¨cnblogsä¸Šå¼„è¿‡ï¼Œä½†æ˜¯æ„Ÿè§‰è¿˜æ˜¯æƒ³é€šè¿‡Hexoå’ŒGithubæ¥å¼„ï¼Œä¸»è¦ç›®çš„æ˜¯è®°å½•ä¸€ä¸‹è‡ªå·±å­¦ä¹ çš„ä¸€äº›ä¸œè¥¿ï¼ŒåŒ…æ‹¬å„ç§è½¯ä»¶ç®—æ³•çš„é…ç½®ã€ä½¿ç”¨ã€ä»¥åŠè¸©è¿‡çš„å‘ç­‰ç­‰ã€‚æœ‰ä¸ªè®°å½•ï¼Œæ–¹ä¾¿è‡ªå·±éœ€è¦çš„æ—¶å€™å¯ä»¥çœ‹çœ‹ï¼ŒåŒæ—¶ï¼Œå¦‚æœæœ‰æœ‹å‹é‡åˆ°äº†ç±»ä¼¼çš„é—®é¢˜ï¼Œå¯ä»¥ç›¸äº’äº¤æµå€Ÿé‰´ã€‚</p><span id="more"></span><h2 id="hexo-é…ç½®">Hexo é…ç½®</h2><p>Hexoçš„é…ç½®ä¸»è¦æ˜¯ç›¸å…³çš„ä¸»é¢˜å•¥çš„ï¼Œç¯å¢ƒé…ç½®å¯ä»¥å‚ç…§Hexoçš„æ–‡æ¡£ï¼Œä¸»é¢˜æˆ‘ç”¨äº†Nextï¼ŒNextç”¨çš„äººå¥½åƒè›®å¤šçš„ï¼ŒæŠ¥äº†å•¥bugä¹Ÿæ–¹ä¾¿è§£å†³ã€‚</p><h2 id="å†™blog">å†™blog</h2><p>é€šè¿‡hexo newxxblogtitlexxï¼Œæ¥å†™blog,ä¸»è¦æ˜¯markdownçš„æ ¼å¼ï¼Œmarkdowndçš„ç›¸å…³è¯­æ³•å¯ä»¥çœ‹è¿™é‡Œï¼š</p><p>https://markdown.com.cn/</p><h2 id="é‡åˆ°çš„é—®é¢˜">é‡åˆ°çš„é—®é¢˜</h2><ol type="1"><li><p>å…¬å¼çš„é—®é¢˜</p><p>ç”¨ghostwriterå†™markdownæ—¶ï¼Œç¼–è¾‘å™¨æ²¡æ³•æ˜¾ç¤ºå…¬å¼ï¼Œæ‰¾æ¥æ‰¾å»æœ€åè¿˜æ˜¯ç”¨vscodeæŠŠï¼Œè¿™ä¸ªå¯ä»¥é¢„è§ˆã€‚ç„¶åæ–°çš„é—®é¢˜å‡ºç°äº†ï¼Œhexoçš„é¡µé¢æ— æ³•æ­£ç¡®æ˜¾ç¤ºå…¬å¼ï¼Œè¿™éœ€è¦å»_cofig.ymlé‡Œï¼Œå°†mathé‚£é‡Œçš„mathjaxå’Œktexçš„enableéƒ½è®¾ä¸ºtrueï¼Œä¸æ˜¯Trueã€‚ç„¶åå°±å¯äº†ã€‚ä½†æ˜¯ï¼å´æ˜¾ç¤ºä¸äº†ä¸‹åˆ’çº¿ï¼Œè‹¦è‹¦æŸ¥è¯¢äº†ä¸€ç•ªï¼Œç”¨pandocçš„æ¸²æŸ“å™¨æ¯”è¾ƒå¥½ï¼Œhexo-render-markedæ¢æˆhexo-renderer-pandocï¼Œéœ€è¦å…ˆå®‰è£…pandocï¼Œå»pandocçš„githubä¸‹è½½æœ€æ–°çš„ç‰ˆæœ¬å®‰è£…å³å¯ã€‚</p></li></ol><p>å‚è€ƒé“¾æ¥å¦‚ä¸‹ï¼š</p><p>https://theme-next.js.org/</p><p>https://hexo.io/zh-cn/docs/</p><p>https://zhuanlan.zhihu.com/p/35988761</p><p>https://blog.csdn.net/weixin_45073562/article/details/120289648</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;æœ€è¿‘ä¸€ç›´æœ‰ä¸ªæƒ³æ³•ï¼Œæƒ³å»å¼„ä¸ªåšå®¢ï¼Œä¹‹å‰æœ‰åœ¨cnblogsä¸Šå¼„è¿‡ï¼Œä½†æ˜¯æ„Ÿè§‰è¿˜æ˜¯æƒ³é€šè¿‡Hexoå’ŒGithubæ¥å¼„ï¼Œä¸»è¦ç›®çš„æ˜¯è®°å½•ä¸€ä¸‹è‡ªå·±å­¦ä¹ çš„ä¸€äº›ä¸œè¥¿ï¼ŒåŒ…æ‹¬å„ç§è½¯ä»¶ç®—æ³•çš„é…ç½®ã€ä½¿ç”¨ã€ä»¥åŠè¸©è¿‡çš„å‘ç­‰ç­‰ã€‚æœ‰ä¸ªè®°å½•ï¼Œæ–¹ä¾¿è‡ªå·±éœ€è¦çš„æ—¶å€™å¯ä»¥çœ‹çœ‹ï¼ŒåŒæ—¶ï¼Œå¦‚æœæœ‰æœ‹å‹é‡åˆ°äº†ç±»ä¼¼çš„é—®é¢˜ï¼Œå¯ä»¥ç›¸äº’äº¤æµå€Ÿé‰´ã€‚&lt;/p&gt;</summary>
    
    
    
    <category term="Tools" scheme="https://young-eng.github.io/YoungBlogs/categories/Tools/"/>
    
    
    <category term="Hexo" scheme="https://young-eng.github.io/YoungBlogs/tags/Hexo/"/>
    
  </entry>
  
</feed>
